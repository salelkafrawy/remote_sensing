{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer custom CNN from MOSAIKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GeoLife data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "CURR_DIR = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "PARENT_DIR = os.path.dirname(CURR_DIR)\n",
    "sys.path.insert(0, \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/remote_sensing\")\n",
    "\n",
    "from dataset.pytorch_dataset import GeoLifeCLEF2022Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "random_state = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/network/scratch/s/sara.ebrahim-elkafrawy/small_geo_data\"  # \"/network/scratch/s/sara.ebrahim-elkafrawy/\" \n",
    "split = \"train\"\n",
    "use_ffcv_loader = False\n",
    "num_species= 17037\n",
    "bands = [\"rgb\"] \n",
    "batch_size = 1\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_train_dataset = GeoLifeCLEF2022Dataset(\n",
    "                root=data_dir,\n",
    "                subset=split,\n",
    "                use_ffcv_loader=use_ffcv_loader,\n",
    "                region=\"both\",\n",
    "                patch_data=bands,\n",
    "                use_rasters=False,\n",
    "                patch_extractor=None,\n",
    "                transform=None,\n",
    "                target_transform=None,\n",
    "                opts=None,\n",
    "            )\n",
    "\n",
    "geo_train_loader = DataLoader(\n",
    "                geo_train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=num_workers,\n",
    "                shuffle=True,\n",
    "                pin_memory=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17037])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same', bias=True))\n",
    "#         self.add_module(nn.ReLU())\n",
    "#         self.add_module(nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "#         self.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same', bias=True))\n",
    "#         self.add_module(nn.ReLU())\n",
    "#         self.add_module(nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "#         self.add_module(nn.Flatten())\n",
    "#         self.add_module(nn.Dropout(0.5))\n",
    "model = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(0.5),\n",
    "      nn.Linear(65536, 512), #50176\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, num_species)\n",
    "      ) \n",
    "model(torch.rand((1, 3, 256, 256))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize weights for the first layer with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (3, 3)\n",
    "num_feats = 32  # also number of patches\n",
    "num_iters = 6   # The online learning part: cycle over the whole dataset 6 times\n",
    "max_patches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=num_feats, \n",
    "                         random_state=random_state,\n",
    "#                          max_no_improvement=5,\n",
    "#                          tol=0.01,\n",
    "#                          max_iter=5,\n",
    "#                          batch_size = kmeans_bs,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial fit of 10000 out of 12024\n",
      "done in 41.43s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "index = 0\n",
    "buffer = []\n",
    "\n",
    "for _ in range(num_iters):\n",
    "    for batch in geo_train_loader:\n",
    "        patches, target, meta = batch\n",
    "        img_np = patches['rgb'].numpy()\n",
    "        img_np = img_np.squeeze(0)\n",
    "        img_np = np.einsum('ijk->jki', img_np)\n",
    "\n",
    "        data = extract_patches_2d(img_np, patch_size, max_patches=max_patches, random_state=random_state)\n",
    "        data = np.reshape(data, (len(data), -1))\n",
    "        buffer.append(data)\n",
    "        index += 1\n",
    "        if index % int(len(geo_train_loader)/10) == 0:\n",
    "            data = np.concatenate(buffer, axis=0)\n",
    "            data -= np.mean(data, axis=0)\n",
    "            data /= np.std(data, axis=0)\n",
    "            kmeans.partial_fit(data)\n",
    "            buffer = []\n",
    "    #             print(f'inertia: {kmeans.inertia_}')\n",
    "        if index % 10000 == 0:\n",
    "            print(\"Partial fit of %4i out of %i\" % (index, num_iters * len(geo_train_loader)))\n",
    "\n",
    "dt = time.time() - t0\n",
    "print(\"done in %.2fs.\" % dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 256, 3), (32, 27))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_np.shape, kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8748642, 2.6060042)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.min(), kmeans.cluster_centers_.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slicing up the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Flatten(start_dim=1, end_dim=-1)\n",
       "  (13): Dropout(p=0.5, inplace=False)\n",
       "  (14): Linear(in_features=65536, out_features=512, bias=True)\n",
       "  (15): ReLU()\n",
       "  (16): Linear(in_features=512, out_features=17037, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lyrs = [3, 6, 9]\n",
    "act_lyrs = [1, 4, 7, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 64, 3, 3]), ReLU())"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())[4][1].data.shape, model[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight ---------------\t torch.Size([32, 3, 3, 3])\n",
      "0.bias ---------------\t torch.Size([32])\n",
      "3.weight ---------------\t torch.Size([64, 32, 3, 3])\n",
      "3.bias ---------------\t torch.Size([64])\n",
      "6.weight ---------------\t torch.Size([128, 64, 3, 3])\n",
      "6.bias ---------------\t torch.Size([128])\n",
      "9.weight ---------------\t torch.Size([256, 128, 3, 3])\n",
      "9.bias ---------------\t torch.Size([256])\n",
      "14.weight ---------------\t torch.Size([512, 65536])\n",
      "14.bias ---------------\t torch.Size([512])\n",
      "16.weight ---------------\t torch.Size([17037, 512])\n",
      "16.bias ---------------\t torch.Size([17037])\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, '---------------\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the weights for hte first layer\n",
    "list(model.named_parameters())[0][1].data = torch.from_numpy(kmeans.cluster_centers_.reshape(32, 3, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(kmeans.cluster_centers_.reshape(32, 3, 3, 3))\n",
    "norm_param = (x - x.mean())/(x.std())\n",
    "model[0].weight.data = norm_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.9434), tensor(2.5193))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())[0][1].data.min(), list(model.named_parameters())[0][1].data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8748642, 2.6060042)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.min(), kmeans.cluster_centers_.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dim = {}\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features_dim[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f2cdd7773a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].register_forward_hook(get_features('relu_layer_1'))\n",
    "model[4].register_forward_hook(get_features('relu_layer_4'))\n",
    "model[7].register_forward_hook(get_features('relu_layer_7'))\n",
    "model[10].register_forward_hook(get_features('relu_layer_10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans for output of relu act layer#1\n",
      "current parameter size: torch.Size([64, 32, 3, 3])\n",
      "current parameter index: 3\n",
      "Initializing parameter#3 with size: torch.Size([64, 32, 3, 3])\n",
      "num_feats:64, num_ch:32, patch_size:(3, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given weight of size [64, 32, 3, 3], expected bias to be 1-dimensional with 64 elements, but got bias of size [64, 32, 3, 3] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m geo_train_loader:\n\u001b[1;32m     50\u001b[0m     patches, target, meta \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 52\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     curr_feats \u001b[38;5;241m=\u001b[39m features_dim[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu_layer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelu_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m#.cpu().numpy())\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     curr_feats \u001b[38;5;241m=\u001b[39m curr_feats\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given weight of size [64, 32, 3, 3], expected bias to be 1-dimensional with 64 elements, but got bias of size [64, 32, 3, 3] instead"
     ]
    }
   ],
   "source": [
    "for layer_idx, relu_idx in enumerate(act_lyrs):\n",
    "\n",
    "    if layer_idx+1 == len(act_lyrs):\n",
    "        break\n",
    "        \n",
    "    print(f'kmeans for output of relu act layer#{relu_idx}')\n",
    "    \n",
    "    curr_param_idx = conv_lyrs[layer_idx]\n",
    "    curr_param_sz = model[curr_param_idx].weight.data.shape\n",
    "\n",
    "#     curr_param_sz = list(model.named_parameters())[curr_param_idx][1].data.shape\n",
    "    print(f'current parameter size: {curr_param_sz}')\n",
    "    print(f'current parameter index: {curr_param_idx}')\n",
    "    \n",
    "#     curr_feat_dim = list(model.named_parameters())[relu_idx][1].shape\n",
    "    \n",
    "#     print(f'current feature layer size: {curr_feat_dim}')\n",
    "    \n",
    "    num_feats = curr_param_sz[0]\n",
    "    num_ch = curr_param_sz[1]\n",
    "    patch_size = (curr_param_sz[2], curr_param_sz[3])\n",
    "    num_iters = 3   # The online learning part: cycle over the whole dataset 6 times\n",
    "    max_patches = int(num_feats/10)\n",
    "\n",
    "#     print(f'current feature map dim: {curr_feat_dim}')\n",
    "    print(f'Initializing parameter#{curr_param_idx} with size: {curr_param_sz}')\n",
    "\n",
    "    print(f'num_feats:{num_feats}, num_ch:{num_ch}, patch_size:{patch_size}')\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_feats, \n",
    "                             random_state=random_state,\n",
    "    #                          max_no_improvement=5,\n",
    "    #                          tol=0.01,\n",
    "    #                          max_iter=5,\n",
    "    #                          batch_size = kmeans_bs,\n",
    "                             verbose=True)\n",
    "\n",
    "    geo_train_loader = DataLoader(\n",
    "                    geo_train_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=num_workers,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "    index = 0\n",
    "    buffer = []\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        for batch in geo_train_loader:\n",
    "            patches, target, meta = batch\n",
    "\n",
    "            output = model(patches['rgb'])\n",
    "            curr_feats = features_dim[f'relu_layer_{relu_idx}'].numpy() #.cpu().numpy())\n",
    "            curr_feats = curr_feats.squeeze(0)\n",
    "            curr_feats = np.einsum('ijk->jki', curr_feats)\n",
    "\n",
    "            data = extract_patches_2d(curr_feats, patch_size, max_patches=max_patches, random_state=random_state)\n",
    "\n",
    "\n",
    "            data = np.reshape(data, (len(data), -1))\n",
    "            buffer.append(data)\n",
    "            index += 1\n",
    "            if index % int(len(geo_train_loader)/10) == 0:\n",
    "        #         print(data)\n",
    "                data = np.concatenate(buffer, axis=0)\n",
    "                data -= np.mean(data, axis=0)\n",
    "                data /= np.std(data, axis=0)\n",
    "                if np.any(np.isnan(data)):\n",
    "                    data = np.nan_to_num(data)\n",
    "                kmeans.partial_fit(data)\n",
    "                buffer = []\n",
    "            if index % 10000 == 0:\n",
    "                print(\"Partial fit of %4i out of %i\" % (index, num_iters * len(geo_train_loader)))\n",
    "\n",
    "\n",
    "    \n",
    "    # change the weights of the corresponding conv layer\n",
    "    x = torch.from_numpy(kmeans.cluster_centers_.reshape(\n",
    "                                            num_feats, \n",
    "                                            num_ch, \n",
    "                                            patch_size[0], \n",
    "                                            patch_size[1])\n",
    "                                        )\n",
    "    norm_param = (x - x.mean())/(x.std())\n",
    "    model[curr_param_idx].weight.data = norm_param\n",
    "\n",
    "#     list(model.named_parameters())[curr_param_idx][1].data = torch.from_numpy(\n",
    "#         kmeans.cluster_centers_.reshape(\n",
    "#                                             num_feats, \n",
    "#                                             num_ch, \n",
    "#                                             patch_size[0], \n",
    "#                                             patch_size[1])\n",
    "#                                         )\n",
    "\n",
    "    # save the model\n",
    "    PATH = \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/ckpts/custom_mosaiks_kmeans.pt\"\n",
    "    torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv2",
   "language": "python",
   "name": "ffcv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
