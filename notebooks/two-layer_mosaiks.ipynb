{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer custom CNN from MOSAIKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GeoLife data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "CURR_DIR = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "PARENT_DIR = os.path.dirname(CURR_DIR)\n",
    "sys.path.insert(0, \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/remote_sensing\")\n",
    "\n",
    "from dataset.pytorch_dataset import GeoLifeCLEF2022Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "random_state = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/network/scratch/s/sara.ebrahim-elkafrawy/small_geo_data\"  # \"/network/scratch/s/sara.ebrahim-elkafrawy/\" \n",
    "split = \"train\"\n",
    "use_ffcv_loader = False\n",
    "num_species= 17037\n",
    "bands = [\"rgb\"] \n",
    "batch_size = 1\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_train_dataset = GeoLifeCLEF2022Dataset(\n",
    "                root=data_dir,\n",
    "                subset=split,\n",
    "                use_ffcv_loader=use_ffcv_loader,\n",
    "                region=\"both\",\n",
    "                patch_data=bands,\n",
    "                use_rasters=False,\n",
    "                patch_extractor=None,\n",
    "                transform=None,\n",
    "                target_transform=None,\n",
    "                opts=None,\n",
    "            )\n",
    "\n",
    "geo_train_loader = DataLoader(\n",
    "                geo_train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=num_workers,\n",
    "                shuffle=True,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "\n",
    "trf = torch.nn.Sequential(\n",
    "    transforms.Resize(size=(224, 224), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.Normalize((106.9413, 114.8733, 104.5285), (51.0005, 44.8595, 43.2014)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17037])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same', bias=True))\n",
    "#         self.add_module(nn.ReLU())\n",
    "#         self.add_module(nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "#         self.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same', bias=True))\n",
    "#         self.add_module(nn.ReLU())\n",
    "#         self.add_module(nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "#         self.add_module(nn.Flatten())\n",
    "#         self.add_module(nn.Dropout(0.5))\n",
    "model = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same', bias=True),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(0.5),\n",
    "      nn.Linear(50176, 512), #50176\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, num_species)\n",
    "      ) \n",
    "model(torch.rand((1, 3, 224, 224))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize weights for the first layer with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (3, 3)\n",
    "num_feats = 32  # also number of patches\n",
    "num_iters = 6   # The online learning part: cycle over the whole dataset 6 times\n",
    "max_patches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=num_feats, \n",
    "                         random_state=random_state,\n",
    "#                          max_no_improvement=5,\n",
    "#                          tol=0.01,\n",
    "#                          max_iter=5,\n",
    "#                          batch_size = kmeans_bs,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial fit of 10000 out of 12024\n",
      "done in 92.82s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "index = 0\n",
    "buffer = []\n",
    "\n",
    "for _ in range(num_iters):\n",
    "    for batch in geo_train_loader:\n",
    "        patches, target, meta = batch\n",
    "        patches['rgb'] = trf(patches['rgb'])\n",
    "            \n",
    "        img_np = patches['rgb'].numpy()\n",
    "        img_np = img_np.squeeze(0)\n",
    "        img_np = np.einsum('ijk->jki', img_np)\n",
    "\n",
    "        data = extract_patches_2d(img_np, patch_size, max_patches=max_patches, random_state=random_state)\n",
    "        data = np.reshape(data, (len(data), -1))\n",
    "        buffer.append(data)\n",
    "        index += 1\n",
    "        if index % int(len(geo_train_loader)/10) == 0:\n",
    "            data = np.concatenate(buffer, axis=0)\n",
    "#             data -= np.mean(data, axis=0)\n",
    "#             data /= np.std(data, axis=0)\n",
    "            kmeans.partial_fit(data)\n",
    "            buffer = []\n",
    "    #             print(f'inertia: {kmeans.inertia_}')\n",
    "        if index % 10000 == 0:\n",
    "            print(\"Partial fit of %4i out of %i\" % (index, num_iters * len(geo_train_loader)))\n",
    "\n",
    "dt = time.time() - t0\n",
    "print(\"done in %.2fs.\" % dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 224, 3), (32, 27))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_np.shape, kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.9179417, 2.6794498)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.min(), kmeans.cluster_centers_.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slicing up the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Flatten(start_dim=1, end_dim=-1)\n",
       "  (13): Dropout(p=0.5, inplace=False)\n",
       "  (14): Linear(in_features=50176, out_features=512, bias=True)\n",
       "  (15): ReLU()\n",
       "  (16): Linear(in_features=512, out_features=17037, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2-conv layers\n",
    "# conv_lyrs = [0, 2]\n",
    "# act_lyrs = [1, 4, 9]\n",
    "\n",
    "# for 4-conv layers\n",
    "conv_lyrs = [0, 2, 4, 6]\n",
    "act_lyrs = [1, 4, 7, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.named_parameters())[4][1].data.shape, model[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight ---------------\t torch.Size([32, 3, 3, 3])\n",
      "0.bias ---------------\t torch.Size([32])\n",
      "3.weight ---------------\t torch.Size([64, 32, 3, 3])\n",
      "3.bias ---------------\t torch.Size([64])\n",
      "6.weight ---------------\t torch.Size([128, 64, 3, 3])\n",
      "6.bias ---------------\t torch.Size([128])\n",
      "9.weight ---------------\t torch.Size([256, 128, 3, 3])\n",
      "9.bias ---------------\t torch.Size([256])\n",
      "14.weight ---------------\t torch.Size([512, 50176])\n",
      "14.bias ---------------\t torch.Size([512])\n",
      "16.weight ---------------\t torch.Size([17037, 512])\n",
      "16.bias ---------------\t torch.Size([17037])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, '---------------\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the weights for hte first layer\n",
    "# list(model.named_parameters())[0][1].data = torch.from_numpy(kmeans.cluster_centers_.reshape(32, 3, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(kmeans.cluster_centers_.reshape(32, 3, 3, 3))\n",
    "norm_param = (x - x.mean())/(x.std())\n",
    "list(model.named_parameters())[0][1].data = norm_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.9193), tensor(2.6334))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())[0][1].data.min(), list(model.named_parameters())[0][1].data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.9179417, 2.6794498)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.min(), kmeans.cluster_centers_.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dim = {}\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features_dim[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[1], model[4], model[7], model[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f5af280f370>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for 2-conv layers\n",
    "# model[1].register_forward_hook(get_features('relu_layer_1'))\n",
    "# model[4].register_forward_hook(get_features('relu_layer_4'))\n",
    "# model[9].register_forward_hook(get_features('relu_layer_9'))\n",
    "\n",
    "\n",
    "# for 4-conv layers\n",
    "model[1].register_forward_hook(get_features('relu_layer_1'))\n",
    "model[4].register_forward_hook(get_features('relu_layer_4'))\n",
    "model[7].register_forward_hook(get_features('relu_layer_7'))\n",
    "model[10].register_forward_hook(get_features('relu_layer_10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lyrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans for output of relu act layer#1\n",
      "current parameter size: torch.Size([64, 32, 3, 3])\n",
      "current parameter index: 2\n",
      "Initializing parameter#2 with size: torch.Size([64, 32, 3, 3])\n",
      "num_feats:64, num_ch:32, patch_size:(3, 3)\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "kmeans for output of relu act layer#4\n",
      "current parameter size: torch.Size([128, 64, 3, 3])\n",
      "current parameter index: 4\n",
      "Initializing parameter#4 with size: torch.Size([128, 64, 3, 3])\n",
      "num_feats:128, num_ch:64, patch_size:(3, 3)\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "kmeans for output of relu act layer#7\n",
      "current parameter size: torch.Size([256, 128, 3, 3])\n",
      "current parameter index: 6\n",
      "Initializing parameter#6 with size: torch.Size([256, 128, 3, 3])\n",
      "num_feats:256, num_ch:128, patch_size:(3, 3)\n",
      "[MiniBatchKMeans] Reassigning 12 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 8 cluster centers.\n"
     ]
    }
   ],
   "source": [
    "for layer_idx, relu_idx in enumerate(act_lyrs):\n",
    "\n",
    "    \n",
    "    if layer_idx+1 == len(conv_lyrs):\n",
    "        break\n",
    "        \n",
    "    print(f'kmeans for output of relu act layer#{relu_idx}')\n",
    "    \n",
    "    curr_param_idx = conv_lyrs[layer_idx+1]\n",
    "    curr_param_sz = list(model.named_parameters())[curr_param_idx][1].data.shape\n",
    "\n",
    "#     curr_param_sz = list(model.named_parameters())[curr_param_idx][1].data.shape\n",
    "    print(f'current parameter size: {curr_param_sz}')\n",
    "    print(f'current parameter index: {curr_param_idx}')\n",
    "    \n",
    "#     curr_feat_dim = list(model.named_parameters())[relu_idx][1].shape\n",
    "    \n",
    "#     print(f'current feature layer size: {curr_feat_dim}')\n",
    "    \n",
    "    num_feats = curr_param_sz[0]\n",
    "    num_ch = curr_param_sz[1]\n",
    "    patch_size = (curr_param_sz[2], curr_param_sz[3])\n",
    "    num_iters = 3   # The online learning part: cycle over the whole dataset 6 times\n",
    "    max_patches = int(num_feats/10)\n",
    "\n",
    "#     print(f'current feature map dim: {curr_feat_dim}')\n",
    "    print(f'Initializing parameter#{curr_param_idx} with size: {curr_param_sz}')\n",
    "\n",
    "    print(f'num_feats:{num_feats}, num_ch:{num_ch}, patch_size:{patch_size}')\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_feats, \n",
    "                             random_state=random_state,\n",
    "    #                          max_no_improvement=5,\n",
    "    #                          tol=0.01,\n",
    "    #                          max_iter=5,\n",
    "    #                          batch_size = kmeans_bs,\n",
    "                             verbose=True)\n",
    "\n",
    "    geo_train_loader = DataLoader(\n",
    "                    geo_train_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=num_workers,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "    index = 0\n",
    "    buffer = []\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        for batch in geo_train_loader:\n",
    "            patches, target, meta = batch\n",
    "            patches['rgb'] = trf(patches['rgb'])\n",
    "            \n",
    "            output = model(patches['rgb'])\n",
    "            curr_feats = features_dim[f'relu_layer_{relu_idx}'].numpy() #.cpu().numpy())\n",
    "            curr_feats = curr_feats.squeeze(0)\n",
    "            curr_feats = np.einsum('ijk->jki', curr_feats)\n",
    "\n",
    "            data = extract_patches_2d(curr_feats, patch_size, max_patches=max_patches, random_state=random_state)\n",
    "\n",
    "\n",
    "            data = np.reshape(data, (len(data), -1))\n",
    "            buffer.append(data)\n",
    "            index += 1\n",
    "            if index % int(len(geo_train_loader)/10) == 0:\n",
    "        #         print(data)\n",
    "                data = np.concatenate(buffer, axis=0)\n",
    "#                 data -= np.mean(data, axis=0)\n",
    "#                 data /= np.std(data, axis=0)\n",
    "                if np.any(np.isnan(data)):\n",
    "                    data = np.nan_to_num(data)\n",
    "                kmeans.partial_fit(data)\n",
    "                buffer = []\n",
    "            if index % 10000 == 0:\n",
    "                print(\"Partial fit of %4i out of %i\" % (index, num_iters * len(geo_train_loader)))\n",
    "\n",
    "\n",
    "    \n",
    "    # change the weights of the corresponding conv layer\n",
    "    x = torch.from_numpy(kmeans.cluster_centers_.reshape(\n",
    "                                            num_feats, \n",
    "                                            num_ch, \n",
    "                                            patch_size[0], \n",
    "                                            patch_size[1])\n",
    "                                        )\n",
    "    norm_param = (x - x.mean())/(x.std())\n",
    "    list(model.named_parameters())[curr_param_idx][1].data = norm_param\n",
    "#     model[curr_param_idx].weight.data = norm_param\n",
    "\n",
    "#     list(model.named_parameters())[curr_param_idx][1].data = torch.from_numpy(\n",
    "#         kmeans.cluster_centers_.reshape(\n",
    "#                                             num_feats, \n",
    "#                                             num_ch, \n",
    "#                                             patch_size[0], \n",
    "#                                             patch_size[1])\n",
    "#                                         )\n",
    "\n",
    "    # save the model\n",
    "    PATH = \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/ckpts/custom_mosaiks_kmeans.pt\"\n",
    "    torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv2",
   "language": "python",
   "name": "ffcv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
