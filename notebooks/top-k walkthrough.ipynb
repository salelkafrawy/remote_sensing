{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents some code to compute some basic baselines.\n",
    "\n",
    "In particular, it shows how to:\n",
    "1. Use the provided validation set\n",
    "2. Compute the top-30 metric\n",
    "3. Save the predictions on the test in the right format for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:38.181545Z",
     "start_time": "2022-02-23T11:36:37.145787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "/network/scratch/s/sara.ebrahim-elkafrawy/ecosystem_project/geolife_kaggle\n",
      "/network/scratch/s/sara.ebrahim-elkafrawy/ecosystem_project/geolife_kaggle/notebooks\n"
     ]
    }
   ],
   "source": [
    "%pylab inline --no-import-all\n",
    "\n",
    "import os\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "\n",
    "CURR_DIR = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "PARENT_DIR = os.path.dirname(CURR_DIR)\n",
    "sys.path.insert(0, \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/geolife_kaggle\")\n",
    "\n",
    "print(PARENT_DIR)\n",
    "print(CURR_DIR)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"/network/scratch/s/sara.ebrahim-elkafrawy\")\n",
    "\n",
    "# Create the path to save submission files\n",
    "SUBMISSION_PATH = Path(\"/network/scratch/s/sara.ebrahim-elkafrawy/ecosystem_project/\")\n",
    "os.makedirs(SUBMISSION_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the official metric, top-30 error rate, for which we provide efficient implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:38.188525Z",
     "start_time": "2022-02-23T11:36:38.183634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function top_30_error_rate in module metrics.metrics:\n",
      "\n",
      "top_30_error_rate(y_true, y_score)\n",
      "    Computes the top-30 error rate.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true: 1d array, [n_samples]\n",
      "        True labels.\n",
      "    y_score: 2d array, [n_samples, n_classes]\n",
      "        Scores for each label.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    float:\n",
      "        Top-30 error rate value.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Complexity: :math:`O( n_\\text{samples} \\times n_\\text{classes} )`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from ..metrics\n",
    "from metrics.metrics import top_30_error_rate\n",
    "help(top_30_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:38.196634Z",
     "start_time": "2022-02-23T11:36:38.190287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function top_k_error_rate_from_sets in module metrics.metrics:\n",
      "\n",
      "top_k_error_rate_from_sets(y_true, s_pred)\n",
      "    Computes the top-k error rate from predicted sets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true: 1d array, [n_samples]\n",
      "        True labels.\n",
      "    s_pred: 2d array, [n_samples, k]\n",
      "        Previously computed top-k sets for each sample.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    float:\n",
      "        Error rate value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics.metrics import top_k_error_rate_from_sets\n",
    "help(top_k_error_rate_from_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For submissions, we will also need to predict the top-30 sets for which we also provide an efficient implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:38.207103Z",
     "start_time": "2022-02-23T11:36:38.198735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predict_top_30_set in module metrics.metrics:\n",
      "\n",
      "predict_top_30_set(y_score)\n",
      "    Predicts the top-30 sets from scores.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_score: 2d array, [n_samples, n_classes]\n",
      "        Scores for each sample and label.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    2d array, [n_samples, 30]:\n",
      "        Predicted top-30 sets for each sample.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Complexity: :math:`O( n_\\text{samples} \\times n_\\text{classes} )`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics.metrics import predict_top_30_set\n",
    "help(predict_top_30_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide an utility function to generate submission files in the right format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:38.217660Z",
     "start_time": "2022-02-23T11:36:38.208957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function generate_submission_file in module submission:\n",
      "\n",
      "generate_submission_file(filename, observation_ids, s_pred, append=False)\n",
      "    Generate submission file for Kaggle\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : string\n",
      "        Submission filename.\n",
      "    observation_ids : 1d array-like\n",
      "        Test observations ids\n",
      "    s_pred : list of 1d array-like\n",
      "        Set predictions for test observations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from submission import generate_submission_file\n",
    "help(generate_submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to load the observation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:39.095055Z",
     "start_time": "2022-02-23T11:36:38.220231Z"
    }
   },
   "outputs": [],
   "source": [
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we retrieve the train/val split provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:39.542831Z",
     "start_time": "2022-02-23T11:36:39.096630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size: 40080 (2.5% of train observations)\n"
     ]
    }
   ],
   "source": [
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "n_val = len(obs_id_val)\n",
    "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the observation data for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:39.578062Z",
     "start_time": "2022-02-23T11:36:39.544489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for testing: 36421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10782781</th>\n",
       "      <td>43.601788</td>\n",
       "      <td>6.940195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364138</th>\n",
       "      <td>46.241711</td>\n",
       "      <td>0.683586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692017</th>\n",
       "      <td>45.181095</td>\n",
       "      <td>1.533459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10222322</th>\n",
       "      <td>46.938450</td>\n",
       "      <td>5.298678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241950</th>\n",
       "      <td>45.017433</td>\n",
       "      <td>0.960736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude\n",
       "observation_id                      \n",
       "10782781        43.601788   6.940195\n",
       "10364138        46.241711   0.683586\n",
       "10692017        45.181095   1.533459\n",
       "10222322        46.938450   5.298678\n",
       "10241950        45.017433   0.960736"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "obs_id_test = df_obs_test.index.values\n",
    "\n",
    "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
    "\n",
    "df_obs_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample submission file\n",
    "\n",
    "In this section, we will demonstrate how to generate the sample submission file provided.\n",
    "\n",
    "To do so, we will use the function `generate_submission_file` from `GLC.submission`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample submission consists in always predicting the first 30 species for all the test observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:39.584215Z",
     "start_time": "2022-02-23T11:36:39.579763Z"
    }
   },
   "outputs": [],
   "source": [
    "first_30_species = np.arange(30)\n",
    "s_pred = np.tile(first_30_species[None], (len(df_obs_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36421, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the associated submission file using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:40.225117Z",
     "start_time": "2022-02-23T11:36:39.586939Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_submission_file(SUBMISSION_PATH / \"sample_submission.csv\", df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant baseline: 30 most observed species\n",
    "\n",
    "The first baseline consists in predicting the 30 most observed species on the train set which corresponds exactly to the \"Top-30 most present species\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:40.368655Z",
     "start_time": "2022-02-23T11:36:40.226559Z"
    }
   },
   "outputs": [],
   "source": [
    "species_distribution = df_obs.loc[obs_id_train][\"species_id\"].value_counts(normalize=True)\n",
    "top_30_most_observed = species_distribution.index.values[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it does not perform very well on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:40.380249Z",
     "start_time": "2022-02-23T11:36:40.370137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-30 error rate: 93.5%\n"
     ]
    }
   ],
   "source": [
    "s_pred = np.tile(top_30_most_observed[None], (n_val, 1))\n",
    "s_pred.shape\n",
    "score = top_k_error_rate_from_sets(y_val, s_pred)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40080,), (40080, 30))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape, s_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40080,), 17006)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape, np.max(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will however generate the associated submission file on the test using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:40.997810Z",
     "start_time": "2022-02-23T11:36:40.381725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute baseline on the test set\n",
    "n_test = len(df_obs_test)\n",
    "s_pred = np.tile(top_30_most_observed[None], (n_test, 1))\n",
    "\n",
    "# Generate the submission file\n",
    "generate_submission_file(SUBMISSION_PATH / \"constant_top_30_most_present_species_baseline.csv\", df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest on environmental vectors\n",
    "\n",
    "A classical approach in ecology is to train Random Forests on environmental vectors.\n",
    "\n",
    "We show here how to do so using [scikit-learn](https://scikit-learn.org/).\n",
    "\n",
    "We start by loading the environmental vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:48.980826Z",
     "start_time": "2022-02-23T11:36:40.999487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/glc/lib/python3.6/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_env = pd.read_csv(DATA_PATH / \"pre-extracted\" / \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_env.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "\n",
    "X_train = df_env.loc[obs_id_train].values\n",
    "X_val = df_env.loc[obs_id_val].values\n",
    "X_test = df_env.loc[obs_id_test].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.4028234663852886e+38, 32448.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.min(), X_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0206739995116313e+37, 5.804305208842461e+37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to handle properly the missing values.\n",
    "\n",
    "For instance, using `SimpleImputer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:36:49.866610Z",
     "start_time": "2022-02-23T11:36:48.984574Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "# imp = SimpleImputer(\n",
    "#     missing_values=np.nan,\n",
    "#     strategy=\"constant\",\n",
    "#     fill_value=np.finfo(np.float32).min,\n",
    "# )\n",
    "# imp.fit(X_train)\n",
    "\n",
    "# X_train = imp.transform(X_train)\n",
    "# X_val = imp.transform(X_val)\n",
    "# X_test = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.4028234663852886e+38, 32448.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.min(), X_val.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training our Random Forest (as there are a lot of observations, over 1.8M, this can take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "\n",
    "X_train = std_scaler.transform(X_train)\n",
    "X_val = std_scaler.transform(X_val)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/network/scratch/s/sara.ebrahim-elkafrawy/ecosystem_project/env_vars_scaler.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the std_scaler\n",
    "import joblib\n",
    "joblib.dump(std_scaler, Path(DATA_PATH / 'ecosystem_project' / 'env_vars_scaler.gz'))\n",
    "# my_scaler = joblib.load('scaler.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_col = df_env.index\n",
    "tmp_arr = std_scaler.transform(df_env.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(tmp_arr, index=idx_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000000</th>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000001</th>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000002</th>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000003</th>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000004</th>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "      <td>0.196704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0        1        2        3        4        5        6   \\\n",
       "observation_id                                                                  \n",
       "10000000        0.16639  0.16639  0.16639  0.16639  0.16639  0.16639  0.16639   \n",
       "10000001        0.16639  0.16639  0.16639  0.16639  0.16639  0.16639  0.16639   \n",
       "10000002        0.16639  0.16639  0.16639  0.16639  0.16639  0.16639  0.16639   \n",
       "10000003        0.16639  0.16639  0.16639  0.16639  0.16639  0.16639  0.16639   \n",
       "10000004        0.16639  0.16639  0.16639  0.16639  0.16639  0.16639  0.16639   \n",
       "\n",
       "                     7        8        9   ...       17       18        19  \\\n",
       "observation_id                             ...                               \n",
       "10000000        0.16639  0.16639  0.16639  ...  0.16639  0.16639  0.196704   \n",
       "10000001        0.16639  0.16639  0.16639  ...  0.16639  0.16639  0.196704   \n",
       "10000002        0.16639  0.16639  0.16639  ...  0.16639  0.16639  0.196704   \n",
       "10000003        0.16639  0.16639  0.16639  ...  0.16639  0.16639  0.196704   \n",
       "10000004        0.16639  0.16639  0.16639  ...  0.16639  0.16639  0.196704   \n",
       "\n",
       "                      20        21        22        23        24        25  \\\n",
       "observation_id                                                               \n",
       "10000000        0.196704  0.196704  0.196704  0.196704  0.196704  0.196704   \n",
       "10000001        0.196704  0.196704  0.196704  0.196704  0.196704  0.196704   \n",
       "10000002        0.196704  0.196704  0.196704  0.196704  0.196704  0.196704   \n",
       "10000003        0.196704  0.196704  0.196704  0.196704  0.196704  0.196704   \n",
       "10000004        0.196704  0.196704  0.196704  0.196704  0.196704  0.196704   \n",
       "\n",
       "                      26  \n",
       "observation_id            \n",
       "10000000        0.196704  \n",
       "10000001        0.196704  \n",
       "10000002        0.196704  \n",
       "10000003        0.196704  \n",
       "10000004        0.196704  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.index == df_env.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.166390\n",
       "1     0.166390\n",
       "2     0.166390\n",
       "3     0.166390\n",
       "4     0.166390\n",
       "5     0.166390\n",
       "6     0.166390\n",
       "7     0.166390\n",
       "8     0.166390\n",
       "9     0.166390\n",
       "10    0.166390\n",
       "11    0.166390\n",
       "12    0.166390\n",
       "13    0.166390\n",
       "14    0.166390\n",
       "15    0.166390\n",
       "16    0.166390\n",
       "17    0.166390\n",
       "18    0.166390\n",
       "19    0.196704\n",
       "20    0.196704\n",
       "21    0.196704\n",
       "22    0.196704\n",
       "23    0.196704\n",
       "24    0.196704\n",
       "25    0.196704\n",
       "26    0.196704\n",
       "Name: 10297014, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[10297014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.009982575861187, 0.196703566683166)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.min(), X_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:39:34.972408Z",
     "start_time": "2022-02-23T11:36:49.868258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=16, n_jobs=-1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = RandomForestClassifier(n_estimators=16, max_depth=10, n_jobs=-1)\n",
    "est.fit(X_train, y_train)\n",
    "# est.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are a lot of classes (over 17K), we need to be cautious when predicting the scores of the model.\n",
    "\n",
    "This can easily take more than 5Go on the validation set.\n",
    "\n",
    "For this reason, we will be predict the top-30 sets by batches using the following generic function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:39:34.978815Z",
     "start_time": "2022-02-23T11:39:34.974222Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_predict(predict_func, X, batch_size=1024):\n",
    "    res = predict_func(X[:1])\n",
    "    n_samples, n_outputs, dtype = X.shape[0], res.shape[1], res.dtype\n",
    "    \n",
    "    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n",
    "    \n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        preds[i:i+batch_size] = predict_func(X_batch)\n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can know compute the top-30 error rate on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1587395, 27), (1587395,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:40:16.449600Z",
     "start_time": "2022-02-23T11:39:34.980251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-30 error rate: 93.2%\n"
     ]
    }
   ],
   "source": [
    "def predict_func(X):\n",
    "    y_score = est.predict_proba(X)\n",
    "    s_pred = predict_top_30_set(y_score)\n",
    "#     print(s_pred.shape)\n",
    "    return s_pred\n",
    "s_val = batch_predict(predict_func, X_val, batch_size=1024)\n",
    "score_val = top_k_error_rate_from_sets(y_val, s_val)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the top-30 sets on the test data and save them in a submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T11:40:54.430717Z",
     "start_time": "2022-02-23T11:40:16.451074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[  16   32  180  221  223  351  459  464  480  482  506  537  546  650\n",
      "  849  939 1013 1397 1425 1584 1682 1731 2132 2426 2638 2700 2767 2844\n",
      " 2865 2998]\n",
      "[  16   32  180  221  223  351  459  464  480  482  506  537  546  650\n",
      "  849  939 1013 1397 1425 1584 1682 1731 2132 2426 2638 2700 2767 2844\n",
      " 2865 2998]\n",
      "False\n",
      "[  5  33  50  72  77  95 163 171 206 231 263 328 386 388 395 422 427 489\n",
      " 493 511 516 519 521 544 596 644 708 770 788 860]\n",
      "[  5  33  50  72  77  95 163 171 206 231 263 328 386 388 395 422 427 489\n",
      " 493 511 516 519 521 544 596 644 708 770 788 860]\n",
      "False\n",
      "[   7    8   29   32  113  117  160  178  236  248  278  313  394  421\n",
      "  425  449  475  486  528  546  581  613  634  638  719  729  826  854\n",
      "  972 1013]\n",
      "[   7    8   29   32  113  117  160  178  236  248  278  313  394  421\n",
      "  425  449  475  486  528  546  581  613  634  638  719  729  826  854\n",
      "  972 1013]\n",
      "False\n",
      "[ 12  50  64  72  77 157 159 167 171 206 277 314 394 427 448 485 493 516\n",
      " 596 644 663 697 708 763 770 788 871 882 896 942]\n",
      "[ 12  50  64  72  77 157 159 167 171 206 277 314 394 427 448 485 493 516\n",
      " 596 644 663 697 708 763 770 788 871 882 896 942]\n",
      "False\n",
      "[  87  311  374 1555 1600 1787 1806 1808 2132 2212 2606 2618 2625 2638\n",
      " 2664 2722 2731 2745 2748 2808 2816 2819 2873 2879 2949 3705 3877 3961\n",
      " 4074 4574]\n",
      "[  87  311  374 1555 1600 1787 1806 1808 2132 2212 2606 2618 2625 2638\n",
      " 2664 2722 2731 2745 2748 2808 2816 2819 2873 2879 2949 3705 3877 3961\n",
      " 4074 4574]\n",
      "False\n",
      "[  87  311  326  374 1555 1600 1787 1806 2061 2096 2132 2212 2606 2618\n",
      " 2638 2647 2664 2689 2722 2731 2745 2766 2819 2837 2873 2879 2949 2981\n",
      " 3508 4574]\n",
      "[  87  311  326  374 1555 1600 1787 1806 2061 2096 2132 2212 2606 2618\n",
      " 2638 2647 2664 2689 2722 2731 2745 2766 2819 2837 2873 2879 2949 2981\n",
      " 3508 4574]\n",
      "False\n",
      "[ 167  439  649  690  708 1000 1713 2495 2506 2574 2591 2617 2618 2625\n",
      " 2660 2680 2709 2803 2871 2877 3059 3126 3264 3270 3337 3427 3460 3879\n",
      " 3912 4282]\n",
      "[ 167  439  649  690  708 1000 1713 2495 2506 2574 2591 2617 2618 2625\n",
      " 2660 2680 2709 2803 2871 2877 3059 3126 3264 3270 3337 3427 3460 3879\n",
      " 3912 4282]\n",
      "False\n",
      "[ 374  605  649  690  782  784  790 1000 1604 1639 1674 1692 1713 2006\n",
      " 2087 2187 2617 2618 2625 2660 2701 2740 2766 2803 2840 3055 3061 3314\n",
      " 4181 4296]\n",
      "[ 374  605  649  690  782  784  790 1000 1604 1639 1674 1692 1713 2006\n",
      " 2087 2187 2617 2618 2625 2660 2701 2740 2766 2803 2840 3055 3061 3314\n",
      " 4181 4296]\n",
      "False\n",
      "[   5  297  811  878 1416 1473 1876 2042 2061 2523 2528 2601 2638 2652\n",
      " 2699 2727 2740 2767 2924 2937 3019 3030 3117 3242 3292 3379 3412 3640\n",
      " 3931 4512]\n",
      "[   5  297  811  878 1416 1473 1876 2042 2061 2523 2528 2601 2638 2652\n",
      " 2699 2727 2740 2767 2924 2937 3019 3030 3117 3242 3292 3379 3412 3640\n",
      " 3931 4512]\n",
      "False\n",
      "[  72  577  936  976 1184 1789 2537 3113 3330 3644 3693 3736 3882 4225\n",
      " 4372 4434 4592 4698 5115 5645 5646 5829 6105 6116 6183 6190 6283 6351\n",
      " 6382 6476]\n",
      "[  72  577  936  976 1184 1789 2537 3113 3330 3644 3693 3736 3882 4225\n",
      " 4372 4434 4592 4698 5115 5645 5646 5829 6105 6116 6183 6190 6283 6351\n",
      " 6382 6476]\n",
      "False\n",
      "[   5 1223 1682 1711 1731 1876 1924 2061 2528 2547 2568 2601 2638 2767\n",
      " 2861 2937 2998 3006 3030 3117 3183 3292 3335 3609 3706 3843 3931 5589\n",
      " 6167 6233]\n",
      "[   5 1223 1682 1711 1731 1876 1924 2061 2528 2547 2568 2601 2638 2767\n",
      " 2861 2937 2998 3006 3030 3117 3183 3292 3335 3609 3706 3843 3931 5589\n",
      " 6167 6233]\n",
      "False\n",
      "[ 192  201  524  714  933  976 1113 1184 2042 2061 2287 2560 2618 2638\n",
      " 2652 2660 2748 2903 2951 3398 3797 3922 4099 4467 4554 4591 4678 5545\n",
      " 6011 6398]\n",
      "[ 192  201  524  714  933  976 1113 1184 2042 2061 2287 2560 2618 2638\n",
      " 2652 2660 2748 2903 2951 3398 3797 3922 4099 4467 4554 4591 4678 5545\n",
      " 6011 6398]\n",
      "False\n",
      "[   5  297  811  878 1416 1473 1876 2042 2061 2523 2528 2601 2638 2652\n",
      " 2699 2727 2740 2767 2924 2937 3019 3030 3117 3242 3292 3379 3412 3640\n",
      " 3931 4512]\n",
      "[   5  297  811  878 1416 1473 1876 2042 2061 2523 2528 2601 2638 2652\n",
      " 2699 2727 2740 2767 2924 2937 3019 3030 3117 3242 3292 3379 3412 3640\n",
      " 3931 4512]\n",
      "False\n",
      "[   5  422  839  976 1546 1698 1916 2528 2660 2699 2708 2843 2904 3110\n",
      " 3242 3315 3330 3481 3892 4120 4340 4427 4915 5158 5541 5598 5606 5779\n",
      " 6162 6411]\n",
      "[   5  422  839  976 1546 1698 1916 2528 2660 2699 2708 2843 2904 3110\n",
      " 3242 3315 3330 3481 3892 4120 4340 4427 4915 5158 5541 5598 5606 5779\n",
      " 6162 6411]\n",
      "False\n",
      "[   8  311  354  376  816 1114 1439 1555 1600 1787 2132 2223 2292 2395\n",
      " 2606 2618 2700 2722 2731 2745 2873 2879 2958 3235 3338 3713 3839 4106\n",
      " 4574 4658]\n",
      "[   8  311  354  376  816 1114 1439 1555 1600 1787 2132 2223 2292 2395\n",
      " 2606 2618 2700 2722 2731 2745 2873 2879 2958 3235 3338 3713 3839 4106\n",
      " 4574 4658]\n",
      "False\n",
      "[ 175  213  374  403  531  649  690 1000 1462 1467 1639 1692 1772 1806\n",
      " 1922 1968 1989 2132 2578 2618 2625 2660 2701 2713 2919 2989 3053 3055\n",
      " 3460 4425]\n",
      "[ 175  213  374  403  531  649  690 1000 1462 1467 1639 1692 1772 1806\n",
      " 1922 1968 1989 2132 2578 2618 2625 2660 2701 2713 2919 2989 3053 3055\n",
      " 3460 4425]\n",
      "False\n",
      "[  67  192  201  524  714  737  876  933  976 1002 1113 1184 1308 1394\n",
      " 1872 2006 2042 2560 2618 2660 2951 3281 3327 3797 3954 4554 4591 5344\n",
      " 5838 6383]\n",
      "[  67  192  201  524  714  737  876  933  976 1002 1113 1184 1308 1394\n",
      " 1872 2006 2042 2560 2618 2660 2951 3281 3327 3797 3954 4554 4591 5344\n",
      " 5838 6383]\n",
      "False\n",
      "[ 123  212  213  374  690 1000 1275 1521 1639 1692 1694 1701 1713 1806\n",
      " 2018 2578 2589 2618 2625 2629 2633 2638 2660 2803 2852 2879 2919 3055\n",
      " 3126 3264]\n",
      "[ 123  212  213  374  690 1000 1275 1521 1639 1692 1694 1701 1713 1806\n",
      " 2018 2578 2589 2618 2625 2629 2633 2638 2660 2803 2852 2879 2919 3055\n",
      " 3126 3264]\n",
      "False\n",
      "[ 175  213  374  403  531  649  690 1000 1119 1467 1555 1639 1692 1772\n",
      " 1806 1891 1922 1968 1989 2132 2618 2625 2660 2919 2951 3053 3055 3460\n",
      " 4239 4314]\n",
      "[ 175  213  374  403  531  649  690 1000 1119 1467 1555 1639 1692 1772\n",
      " 1806 1891 1922 1968 1989 2132 2618 2625 2660 2919 2951 3053 3055 3460\n",
      " 4239 4314]\n",
      "False\n",
      "[   5  318  628  878 1054 1273 1873 1876 2528 2568 2601 2730 2747 2901\n",
      " 2921 2937 2965 2981 3117 3292 3353 3640 3891 3931 4139 4278 4450 4512\n",
      " 4622 4687]\n",
      "[   5  318  628  878 1054 1273 1873 1876 2528 2568 2601 2730 2747 2901\n",
      " 2921 2937 2965 2981 3117 3292 3353 3640 3891 3931 4139 4278 4450 4512\n",
      " 4622 4687]\n",
      "False\n",
      "[ 213  311  374  580  690 1521 1553 1555 1639 1674 1806 1815 1854 1968\n",
      " 2061 2606 2618 2625 2629 2638 2660 2722 2819 2852 2879 2919 2949 2981\n",
      " 3055 3126]\n",
      "[ 213  311  374  580  690 1521 1553 1555 1639 1674 1806 1815 1854 1968\n",
      " 2061 2606 2618 2625 2629 2638 2660 2722 2819 2852 2879 2919 2949 2981\n",
      " 3055 3126]\n",
      "False\n",
      "[ 436  524  690  927  976 1000 1066 1123 1275 1500 1692 1694 1713 1968\n",
      " 2018 2212 2618 2638 2657 2660 2803 2980 3104 3126 3264 3456 3824 3879\n",
      " 4184 4522]\n",
      "[ 436  524  690  927  976 1000 1066 1123 1275 1500 1692 1694 1713 1968\n",
      " 2018 2212 2618 2638 2657 2660 2803 2980 3104 3126 3264 3456 3824 3879\n",
      " 4184 4522]\n"
     ]
    }
   ],
   "source": [
    "# Compute baseline on the test set\n",
    "s_pred = batch_predict(predict_func, X_test, batch_size=1024)\n",
    "\n",
    "# Generate the submission file\n",
    "generate_submission_file(SUBMISSION_PATH / \"random_forest_on_environmental_vectors.csv\", df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 5, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "k = 4\n",
    "x = np.array([3, 4, 2, 1, 10, 8])\n",
    "x_ids = np.argpartition(x, k)[-k:]\n",
    "x_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10,  8,  4,  3], dtype=torch.int32), tensor([4, 5, 1, 0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor([3, 4, 2, 1, 10, 8])\n",
    "vals, idx = torch.topk(y, k)\n",
    "vals.type(torch.int), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 5, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.flip(dims=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_np = idx.numpy()\n",
    "(tmp_np == x_ids).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc",
   "language": "python",
   "name": "glc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {
    "height": "856.867px",
    "left": "0px",
    "right": "1468px",
    "top": "111.133px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
