{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/pl_bolts/utils/warnings.py:30: UserWarning: You want to use `gym` which is not installed yet, install it with `pip install gym`.\n",
      "  stdout_func(\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import timeit\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple, Type, cast\n",
    "\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "from pytorch_lightning.profiler import AdvancedProfiler, SimpleProfiler\n",
    "from pytorch_lightning.profiler.pytorch import PyTorchProfiler\n",
    "\n",
    "from models.moco2_module import MocoV2\n",
    "from pl_bolts.models.self_supervised.moco.callbacks import MocoLRScheduler\n",
    "\n",
    "from dataset.ssl.ssl_geolife_datamodule import GeoLifeDataModule\n",
    "from models.ssl_online import SSLOnlineEvaluator\n",
    "from models.utils import InputMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_opts = {'use_ffcv_loader': False,\n",
    "            'batch_size': 32,\n",
    "            'num_workers': 2,\n",
    "            'data_dir': \"/network/scratch/s/sara.ebrahim-elkafrawy/small_geo_data/\",\n",
    "            'log_dir': \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/exps/debug_exp\",\n",
    "            'config_file': \"debug-exp.yaml\",\n",
    "            'random_init_path': \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/ckpts/resnet50_random_init\",\n",
    "            'ckpt_file': \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/ckpts/first_epoch_57_bs64_numworker4.ckpt\",\n",
    "            'max_epochs': 2,\n",
    "            'gpus': 1,\n",
    "#             'data':{\n",
    "#                   'loaders':\n",
    "#                             {\n",
    "#                                 'num_workers': 2,   # 32\n",
    "#                                 'batch_size': 32   # 256\n",
    "#                             },\n",
    "#                   'datatype': \"img\",  \n",
    "#                   'bands':  [\"rgb\"],  \n",
    "#                   'splits':{ \n",
    "#                             'train': val,  \n",
    "#                             'val': val,\n",
    "#                             'test': test,\n",
    "#                           },\n",
    "#                   'transforms':{\n",
    "#                         - name: crop\n",
    "#                           ignore: True\n",
    "#                           p: 0.5\n",
    "#                           center: true # disable randomness, crop around the image's center\n",
    "#                           size: [256, 256]\n",
    "#                         - name: resize\n",
    "#                           ignore: False\n",
    "#                           size: [224,224]\n",
    "#                         - name: hflip\n",
    "#                           ignore: \"val\"\n",
    "#                           p: 0.5\n",
    "#                         - name: vflip\n",
    "#                           ignore: \"val\"\n",
    "#                           p: 0.5    \n",
    "#                         - name: normalize\n",
    "#                           ignore: False\n",
    "#                           means: [106.94150444, 114.87315837, 104.52826283]   # [0.4194, 0.4505, 0.4099], \n",
    "#                           std: [50.59516823, 44.13010964, 41.84300729]        # [0.20, 0.1759, 0.1694]\n",
    "#                           band: \"rgb\"\n",
    "#                         - name: normalize\n",
    "#                           ignore: True\n",
    "#                           means: [131.0458]     # 0.5139\n",
    "#                           std: [53.0884]        # 0.2082\n",
    "#                           band: \"near_ir\"\n",
    "#                         - name: normalize\n",
    "#                           ignore: True\n",
    "#                           means: [298.1693]\n",
    "#                           std: [459.3285]\n",
    "#                           band: \"altitude\"\n",
    "#                         - name: normalize\n",
    "#                           ignore: True\n",
    "#                           means: [17.4200]\n",
    "#                           std: [9.5173]\n",
    "#                           band: \"landcover\"\n",
    "#                               }\n",
    "#                     },\n",
    "            \n",
    "            'ssl':\n",
    "                    {'learning_rate': 0.03,\n",
    "                      'ssl_pretrained': False,\n",
    "                      'num_keys': 3,\n",
    "                      'schedule': [120, 160],\n",
    "                      'base_encoder': 'resnet50',\n",
    "                      'emb_dim': 128,\n",
    "                      'num_workers': 32,\n",
    "                      'num_negatives': 16384,\n",
    "                      'encoder_momentum': 0.999,\n",
    "                      'softmax_temperature': 0.07,\n",
    "                      'momentum': 0.9,\n",
    "                      'weight_decay': 1e-4,\n",
    "                      'batch_size': 256,\n",
    "                      'use_ddp': False,\n",
    "                      'use_ddp2': False,\n",
    "                    #   accelerator: gpu\n",
    "                    #   strategy: ddp\n",
    "                    #   devices: 1\n",
    "                    #   num_nodes: 1\n",
    "                      'online_max_epochs': 2,\n",
    "                      'online_val_every_n_epoch': 1},}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_opts = cast(DictConfig, exp_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_configs = OmegaConf.merge({}, exp_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_configs.ssl.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoLife dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import torch\n",
    "\n",
    "CURR_DIR = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "PARENT_DIR = os.path.dirname(CURR_DIR)\n",
    "sys.path.insert(0, CURR_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.ffcv_loader.dataset_ffcv import GeoLifeCLEF2022DatasetFFCV\n",
    "from dataset.pytorch_dataset import GeoLifeCLEF2022Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/tmp_geo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GeoLifeCLEF2022Dataset(\n",
    "    exp_configs.data_dir,\n",
    "    \"train\",\n",
    "    region=\"both\",\n",
    "    patch_data=\"all\", # self.opts.data.bands,\n",
    "    use_rasters=False,\n",
    "    patch_extractor=None,\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    "    )\n",
    "\n",
    "val_dataset = GeoLifeCLEF2022Dataset(\n",
    "        exp_configs.data_dir,\n",
    "        \"val\",\n",
    "        region=\"both\",\n",
    "        patch_data=\"all\", #self.opts.data.bands,\n",
    "        use_rasters=False,\n",
    "        patch_extractor=None,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "    )\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               num_workers=exp_configs.num_workers, \n",
    "                                               batch_size=exp_configs.batch_size,\n",
    "                                               pin_memory=True,\n",
    "                                               drop_last=True,\n",
    "                                               shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                              num_workers=exp_configs.num_workers, \n",
    "                                              batch_size=exp_configs.batch_size,\n",
    "                                              pin_memory=True,\n",
    "                                              drop_last=False,\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = MocoV2(exp_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=exp_configs.log_dir, filename='{epoch}')\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "moco_scheduler = MocoLRScheduler(\n",
    "    initial_lr=exp_configs.ssl.learning_rate, \n",
    "    schedule=exp_configs.ssl.schedule, \n",
    "    max_epochs=exp_configs.max_epochs)\n",
    "\n",
    "# online_evaluator = SSLOnlineEvaluator(\n",
    "#     exp_configs,\n",
    "#     data_dir=exp_configs.data_dir,\n",
    "#     z_dim=model.mlp_dim,\n",
    "# )\n",
    "\n",
    "trainer_args = {}\n",
    "trainer_args[\"callbacks\"] = [\n",
    "    checkpoint_callback,\n",
    "    lr_monitor,\n",
    "    moco_scheduler,\n",
    "#     online_evaluator,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocessing is handled by SLURM.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "        enable_progress_bar=True,\n",
    "        default_root_dir=exp_configs.log_dir,\n",
    "        max_epochs=exp_configs.max_epochs,\n",
    "        gpus=exp_configs.gpus,\n",
    "#         accelerator=exp_configs.ssl.accelerator,\n",
    "#         devices=exp_configs.ssl.devices, \n",
    "#         num_nodes=exp_configs.ssl.num_nodes, \n",
    "#         strategy=exp_configs.ssl.strategy,\n",
    "#         logger=comet_logger,\n",
    "#         log_every_n_steps=trainer_args[\"log_every_n_steps\"],\n",
    "#         callbacks=trainer_args[\"callbacks\"],\n",
    "        overfit_batches=0.0,  ## make sure it is 0.0 when training\n",
    "        precision=16,\n",
    "        accumulate_grad_batches=int(exp_configs.batch_size / 4),\n",
    "#         progress_bar_refresh_rate=0,\n",
    "        #         strategy=\"ddp_find_unused_parameters_false\",\n",
    "        #         distributed_backend='ddp',\n",
    "        #         profiler=profiler,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:131: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.4.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n",
      "\n",
      "check self.strategy.restore_checkpoint_after_setup\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [1]:  exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/ckpts/first_epoch_57_bs64_numworker4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sara.ebrahim-elkafrawy/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:342: UserWarning: The dirpath has changed from '/network/scratch/s/sara.ebrahim-elkafrawy/ecosystem_project/exps/ssl_seco_resnet50_exp' to '/home/mila/s/sara.ebrahim-elkafrawy/scratch/ecosystem_project/exps/debug_exp/lightning_logs/version_2081243/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                | Params\n",
      "---------------------------------------------------------\n",
      "0 | transforms_img   | DataAugmentationRGB | 0     \n",
      "1 | transforms_jit   | DataAugmentationRGB | 0     \n",
      "2 | transforms_gauss | DataAugmentationRGB | 0     \n",
      "3 | encoder_q        | Sequential          | 23.5 M\n",
      "4 | encoder_k        | Sequential          | 23.5 M\n",
      "5 | heads_q          | ModuleList          | 13.4 M\n",
      "6 | heads_k          | ModuleList          | 13.4 M\n",
      "---------------------------------------------------------\n",
      "36.9 M    Trainable params\n",
      "36.9 M    Non-trainable params\n",
      "73.8 M    Total params\n",
      "147.536   Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "You restored a checkpoint with current_epoch=58, but you have set Trainer(max_epochs=2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_configs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m stop \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;66;03m# restore optimizers, etc.\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring training state\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1234\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_training_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m   1238\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:199\u001b[0m, in \u001b[0;36mCheckpointConnector.restore_training_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_precision_plugin_state()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# restore loops and their progress\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_loops\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# restore optimizers and schedulers state\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ffcv2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:293\u001b[0m, in \u001b[0;36mCheckpointConnector.restore_loops\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# crash if max_epochs is lower then the current epoch from the checkpoint\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_epochs\n\u001b[1;32m    292\u001b[0m ):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou restored a checkpoint with current_epoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but you have set Trainer(max_epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m     )\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: You restored a checkpoint with current_epoch=58, but you have set Trainer(max_epochs=2)."
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "trainer.fit(model, \n",
    "            train_dataloaders=train_dataloader, \n",
    "            val_dataloaders=val_dataloader, \n",
    "            ckpt_path=exp_configs.ckpt_file,)\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv2",
   "language": "python",
   "name": "ffcv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
